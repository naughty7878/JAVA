## 0001
***
### 给你50亿行字符串，机器4G内存（只能一台机器），找出重复次数最多的那行字符串？（以行为单位，每行不超过10个字符）
#### 答：
> 50亿行字符串 -> 假设每行10个字符串，500亿字符串 -> 500 0000 0000 byte 
> 500 0000 0000 byte -> 500 0000 0 kb -> 500 00 mb -> 50 gb 数据
> -> 机器4G内存，分割文件 -> 分割500份，每分则为 100 mb  
> 
> **思路**
> 
> - 首先把文件分开
> - 针对每个文件hash遍历去重，统计每个词语的频率
> - 使用堆进行遍历
> - 把堆归并起来
> 
> **具体的方案** 
> 
> 1. 分治   
	顺序读文件中，每一行看作一个词，对于每个词c，取hash(c)%2000，保证同一个字符串在同一个文件中，然后按照该值存到2000个小文件中。这样每个文件大概是500k左右。
> > **注意**  
> > 如果其中的有的文件超过了1M大小，还可以按照类似的方法继续往下分，直到分解得到的小文件的大小都不超过1M。
> 
> 2. hash遍历     
	对每个小文件，用hash的方式统计每个文件中出现的词以及相应的频率
> 3. 堆遍历  
	用 最小堆取出出现频率最大的100个词，并把100个词及相应的频率存入文件，这样又得到了5000个文件。
> 4. 归并整合  
	下一步就是把这5000个文件进行归并（类似与归并排序）的过程了
>
#### 百度答案：
> 根据50亿和4G的限制，直接想到切割多少份文件后，争取这一份文件大小够加载4G内存进行解析（当然当个文件尽可能接近内存大小，充分利用内存读取速度，提供整体计算时间），大概分为500比较合适（每个文件大概100m左右，加载内存解析够了），让后按照hash(行号)%500进行分配存储，分别对每个文件排序后再存在有序大小字符串文件，通过选择排序逐步递归筛累计结果
> 
> **总结**  
> 
> 海量数据处理算法（top K问题）  
> [https://www.cnblogs.com/h--d/p/14965418.html](https://www.cnblogs.com/h--d/p/14965418.html])


## 0002
***
### 设计一个算法，实现两个 10g 大文件在 10m 的内存中将两个大文件中 "重复的值" 放进第三个文件
#### 答：
> **百度答案**
> 1. 分治  
> - 对第一个10g文件进行hash存储( hash(值)/2560 )，将值存放到10g/4m=2560个文件中，每个文件4m，序号1.2.3...
> - 再对第二个10g文件进行同样操作
> 2. 遍历比较
> 将同序号的两个4m左右的文件放到内存中，对他们进行遍历比较（因为他们都是hash存储到同一个序号的文件，所以如果有相同的值肯定能够比较出来，其他序号的文件不可能有相同的值了），
	 比较到相同的值后将其存放到剩余的2m内存中，最后再将这2m内存中的内容写回磁盘第三个文件，
	 然后继续读取序号为2的两个文件进行同样的过程
> 原文链接：https://blog.csdn.net/qq_35642036/article/details/82854063


## 0003
***
### 快速排序的平均复杂多少?最坏情况是什么?
#### 答：
> **基本思想**  
> 1. 先从数列中取出一个数作为基准数。
> 2. 分区过程，将比这个数大的数全放到它的右边，小于或等于它的数全放到它的左边。
> 3. 重复1-2步骤
> 4. 再对左右区间重复第二步，直到各区间只有一个数。  
> 
> 十大经典排序算法：  
> https://www.cnblogs.com/h--d/p/14888924.html


## 0003
***
### 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url
#### 答：
> **分析**  
> - 每个文件的大小约为5亿×64≈320G，远远大于内存大小。考虑采取分而治之的方法。
> 
> **解法**  
> 1. 分治：遍历文件a，对每个url求Hash%1000，根据值将url分别存储到1000个小文件中，每个小文件约为300M。文件b采用同样hash策略分到另外的1000个小文件中。
> 上述两组小文件中，只有相同编号的小文件才可能有相同元素。
> 2. Hash_set：读取a组中一个小文件的url存储到hash_set中，然后遍历b组中相同编号小文件的每个url， 
> 查看是否在刚才构建的hash_set中。如果存在，则存到输出文件里。
>
> 原文链接：https://blog.csdn.net/qq_35642036/article/details/82854063


## 0005
***
### 一致hash算法
> 1、平衡性（Balance）：平衡性是指哈希的结果能够尽可能分布在所有的缓冲(Cache)中去，这样可以使得所有的缓冲空间得到利用。很多哈希算法都能够满足这一条件。
> 
> 2、单调性（Monotonicity）：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应该能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会映射到旧的缓冲集合中的其他缓冲区。
>
> 3、分散性（Spread）：在分布式环境中，终端有可能看不到所有的缓冲，而只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上去，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应该能够尽量避免不一致的情况发生，也就是尽量降低分散性。
>
> 4、负载（Load）：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射到不同的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。
> 在分布式集群中，对机器的添加删除，或者机器故障后自动脱落集群这些操作是分布式集群管理最基本的功能。如果采用常用的hash(object)%N算法，那么在有机器添加或者删除后，很多原有的数据就无法找到了，这样严重的违反了单调性原则。
>
> ————————————————
>
> 版权声明：本文为CSDN博主「学之以恒_大道至简」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
> 原文链接：https://blog.csdn.net/cb_lcl/article/details/81448570